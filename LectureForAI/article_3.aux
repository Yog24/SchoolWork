\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{Vaswani:2017at}
\citation{Radford:2018tf}
\citation{Devlin:2018br}
\citation{zhao2024surveylargelanguagemodels}
\citation{zhao2024surveylargelanguagemodels}
\citation{Bender:2021ai}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{Introduction}{1}{Doc-Start}\protected@file@percent }
\citation{vaswani2023attentionneed}
\citation{vaswani2023attentionneed}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Chronological development of large language models (LLMs) from 2019 to 2023.\cite  {zhao2024surveylargelanguagemodels}}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dev}{{1}{2}{Chronological development of large language models (LLMs) from 2019 to 2023.\cite {zhao2024surveylargelanguagemodels}}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Overview of Core-tech in LLMs}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Objective of Language Modeling}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Transformer Architecture}{2}{subsubsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The encoder-decoder structure of the Transformer architecture Taken from “Attention Is All You Need“\cite  {vaswani2023attentionneed}}}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:tran}{{2}{2}{The encoder-decoder structure of the Transformer architecture Taken from “Attention Is All You Need“\cite {vaswani2023attentionneed}}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Self-Attention Mechanism}{2}{subsubsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Multi-Head Attention}{2}{subsubsection.1.1.3}\protected@file@percent }
\citation{wu2024roleplay}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Positional Encoding}{3}{subsubsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Feed-Forward Neural Network (FFN)}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Training Objective}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Optimization}{3}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Scaling and Fine-Tuning}{3}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Industry Application Scenarios}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Content Creation}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Script Writing}{3}{paragraph*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Chatbot}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Customer Support}{3}{paragraph*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Q\&A Systems}{3}{paragraph*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Various LLM applications around world}}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:llmapp}{{3}{4}{Various LLM applications around world}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Healcare}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Diagnostic Assistance}{4}{paragraph*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pharmaceutical}{4}{paragraph*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Education}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Personalized Learning}{4}{paragraph*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Language Learning}{4}{paragraph*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Finace}{4}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Financial Analysis}{4}{paragraph*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Opportunities}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Efficiency}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model pruning and distillation}{4}{paragraph*.12}\protected@file@percent }
\citation{hinton2015distillingknowledgeneuralnetwork}
\citation{gao2024retrievalaugmentedgenerationlargelanguage}
\citation{gao2024retrievalaugmentedgenerationlargelanguage}
\citation{website}
\citation{gao2024retrievalaugmentedgenerationlargelanguage}
\citation{he2024doespromptformattingimpact}
\citation{he2024doespromptformattingimpact}
\citation{he2024doespromptformattingimpact}
\citation{he2024doespromptformattingimpact}
\citation{website-llm-market}
\citation{website-llm-mulins}
\citation{csdn-person-rec}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Content Quality}{5}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces RAG diagram}}{5}{figure.caption.13}\protected@file@percent }
\newlabel{fig:rag}{{4}{5}{RAG diagram}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {paragraph}{RAG}{5}{paragraph*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example to demonstrate how prompt for-matting impacts GPT-35-turbo-16k-0613 model's per-formance\cite  {he2024doespromptformattingimpact}}}{5}{figure.caption.15}\protected@file@percent }
\newlabel{fig:prompt}{{5}{5}{An example to demonstrate how prompt for-matting impacts GPT-35-turbo-16k-0613 model's per-formance\cite {he2024doespromptformattingimpact}}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {paragraph}{Prompt}{5}{paragraph*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Expanding Market Scale}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Rapidly growing market size}{5}{paragraph*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Multi-industry Application}{5}{paragraph*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Personalized Service}{5}{subsection.3.4}\protected@file@percent }
\citation{stackoverflow-dataprivacy}
\citation{yang2024problematictokenstokenizerbias}
\citation{yang2024problematictokenstokenizerbias}
\citation{yang2024problematictokenstokenizerbias}
\citation{10.1145/3442188.3445922}
\citation{unres}
\citation{unnes}
\citation{gptcost}
\@writefile{toc}{\contentsline {section}{\numberline {4}Challenges}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data Privacy}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Data Resources}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Classification of abnormal Chinese tokens by content type.\cite  {yang2024problematictokenstokenizerbias}}}{6}{figure.caption.19}\protected@file@percent }
\newlabel{fig:token_samples}{{6}{6}{Classification of abnormal Chinese tokens by content type.\cite {yang2024problematictokenstokenizerbias}}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ethics \& Bias}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Costs}{6}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{High Computational Costs}{6}{paragraph*.20}\protected@file@percent }
\citation{reducecost}
\citation{googlereport}
\bibstyle{unsrt}
\bibdata{sample.bib}
\bibcite{Vaswani:2017at}{1}
\bibcite{Radford:2018tf}{2}
\bibcite{Devlin:2018br}{3}
\bibcite{zhao2024surveylargelanguagemodels}{4}
\bibcite{Bender:2021ai}{5}
\bibcite{vaswani2023attentionneed}{6}
\bibcite{wu2024roleplay}{7}
\bibcite{hinton2015distillingknowledgeneuralnetwork}{8}
\bibcite{gao2024retrievalaugmentedgenerationlargelanguage}{9}
\bibcite{website}{10}
\@writefile{toc}{\contentsline {paragraph}{Resources Consumption}{7}{paragraph*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Acknowledgments}{7}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{7}{section*.23}\protected@file@percent }
\bibcite{he2024doespromptformattingimpact}{11}
\bibcite{website-llm-market}{12}
\bibcite{website-llm-mulins}{13}
\bibcite{csdn-person-rec}{14}
\bibcite{stackoverflow-dataprivacy}{15}
\bibcite{yang2024problematictokenstokenizerbias}{16}
\bibcite{10.1145/3442188.3445922}{17}
\bibcite{unres}{18}
\bibcite{unnes}{19}
\bibcite{gptcost}{20}
\bibcite{reducecost}{21}
\bibcite{googlereport}{22}
\ttl@finishall
\newlabel{LastPage}{{5}{8}{}{page.8}{}}
\gdef\lastpage@lastpage{8}
\gdef\lastpage@lastpageHy{8}
\gdef \@abspage@last{8}
